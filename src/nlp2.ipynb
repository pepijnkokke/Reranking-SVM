{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import with_statement\n",
    "\n",
    "import collections\n",
    "import gzip\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Spacy library\n",
    "\n",
    "[Spacy](http://spacy.io) is an NLP library which is ready to be used in production settings. This library will help us find features for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load('en')\n",
    "de_nlp = spacy.load('de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the NLTK library\n",
    "\n",
    "We will use the [NLTK library](NLTK) for other features we want to extract from our data. As well as use the BLUE scoring algorithm in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import modified_precision, corpus_bleu\n",
    "from nltk.util                 import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BLEU(reference,candidate):\n",
    "    \"\"\"\n",
    "    Compute the BLEU score for a given candidate sentence, with respect to a\n",
    "    given reference sentence.\n",
    "\n",
    "    reference: the reference translation\n",
    "    candidate: the candidate translation\n",
    "    \"\"\"\n",
    "    return float(modified_precision([reference],candidate,n=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_feature(s,nlp,n=1,simple_pos=False):\n",
    "    \"\"\"\n",
    "    Compute the POS feature vector given a sentence and an instance of spaCy.\n",
    "    The POS feature vector is a vector which indicates, per POS-tag of the\n",
    "    language, what ratio of the words in the sentence have this POS-tag.\n",
    "\n",
    "    s  : input sentence\n",
    "    nlp: instance of spaCy nlp\n",
    "    n  : the size of the n-grams over which the vector is built\n",
    "    \"\"\"\n",
    "    doc       = nlp(s,tag=True,parse=False,entity=False)\n",
    "    \n",
    "    # Compute the PoS-tags using spaCy.\n",
    "    if simple_pos:\n",
    "        pos_tags  = [tok.pos_ for tok in doc]\n",
    "        pos_sible = spacy.parts_of_speech.NAMES.values()\n",
    "    else:\n",
    "        pos_tags  = [tok.tag_ for tok in doc] \n",
    "        pos_sible = nlp.tagger.tag_names\n",
    "        \n",
    "    # Compute the n-grams of the PoS-tags.\n",
    "    pos_tags  = list(ngrams(pos_tags,n))\n",
    "    pos_sible = itertools.combinations(pos_sible,n)\n",
    "    \n",
    "    pos_count = collections.Counter(pos_tags)\n",
    "    pos_count = map(lambda tag: pos_count[tag] / len(pos_tags), pos_sible)\n",
    "    return pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_s = u'Hello, world. Here are two sentences.'\n",
    "de_s = u'Ich bin ein Berliner.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: print the simple unigram PoS-feature for an English sentence.\n",
    "en_pos = pos_feature(en_s,en_nlp,n=1,simple_pos=True)\n",
    "print(len(en_pos))\n",
    "print(map(lambda x: round(x,2),en_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: print the complex unigram POS-feature for a German sentence.\n",
    "de_pos = pos_feature(de_s,de_nlp,n=1)\n",
    "print(len(de_pos))\n",
    "print(map(lambda x: round(x,2),de_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example: print the first 100 values of the simple bigram POS-feature for an German sentence.\n",
    "de_pos = pos_feature(de_s,de_nlp,n=2,simple_pos=True)\n",
    "print(len(de_pos))\n",
    "print(map(lambda x: round(x,2),de_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: print the first 24 values in the sentence vector for an English sentence.\n",
    "en_doc = en_nlp(en_s)\n",
    "print(len(en_doc.vector))\n",
    "print(en_doc.vector[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: print the first 24 values in the sentence vector for a German sentence.\n",
    "de_doc = de_nlp(de_s)\n",
    "print(len(de_doc.vector))\n",
    "print(de_doc.vector[:24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create constants for the paths to all data files.\n",
    "DATA_DIR         = os.path.abspath(os.path.join('..','data'))\n",
    "BASELINE_WEIGHTS = os.path.join(DATA_DIR,'baseline.weights')\n",
    "DEV_BEST         = os.path.join(DATA_DIR,'nlp2-dev.1000best')\n",
    "DEV_DE           = os.path.join(DATA_DIR,'nlp2-dev.de')\n",
    "DEV_EN_PLF       = os.path.join(DATA_DIR,'nlp2-dev.en.pw.plf-100')\n",
    "DEV_EN           = os.path.join(DATA_DIR,'nlp2-dev.en.s')\n",
    "TEST_BEST        = os.path.join(DATA_DIR,'nlp2-test.1000best')\n",
    "TEST_DE          = os.path.join(DATA_DIR,'nlp2-test.de')\n",
    "TEST_EN_PLF      = os.path.join(DATA_DIR,'nlp2-test.en.pw.plf-100')\n",
    "TEST_EN          = os.path.join(DATA_DIR,'nlp2-test.en.s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_candidate(s):\n",
    "    \"\"\"\n",
    "    Parse a candidate translation (a line from the 1000-best files) into\n",
    "    a tuple containing (in order):\n",
    "    \n",
    "        k:              the 0-based sentence id           (int)\n",
    "        source:         the source sentence               (str)\n",
    "        target:         the translated sentence           (str)\n",
    "        segments:       the segments and their alignments (list[(str,(int,int))])\n",
    "        feature_vector: the feature vector                ({str: list[float]})\n",
    "        score:          the score assigned by MOSES       (float)\n",
    "        alignments:     the alignments                    ([(int,int)])\n",
    "\n",
    "    Note: alignments in the \"segments\" field are pairs of states in the\n",
    "    input lattice, whereas the alignments in the \"alignments\" field are\n",
    "    pairs of a state in the input lattice together with the position of\n",
    "    the output word.\n",
    "    \"\"\"\n",
    "    k, segments_and_alignments, feature_vector, score, alignments, source = s.split(' ||| ')\n",
    "    \n",
    "    # Parse an id as an integer\n",
    "    k = int(k)\n",
    "    \n",
    "    # Parse a candidate translation (with alignments) into a sentence.\n",
    "    segments_and_alignments = map(lambda s: s.strip(),\n",
    "                                  re.split(r'\\|(\\d+\\-\\d+)\\|', segments_and_alignments))\n",
    "    segments = segments_and_alignments[0::2]\n",
    "    target = ' '.join(segments)\n",
    "    \n",
    "    # Parse a candidate translation (with alignments) into a list of segments.\n",
    "    segment_alignments = map(lambda s: tuple(map(int,s.strip().split('-'))), \n",
    "                             segments_and_alignments[1::2])\n",
    "    segments = zip(segments,segment_alignments)\n",
    "    \n",
    "    # Parse a feature vector string into a dictionary.\n",
    "    feature_vector = re.split(r'([A-Za-z]+0?)=', feature_vector)\n",
    "    feature_names  = feature_vector[1::2]\n",
    "    feature_values = map(lambda s: map(float,s.strip().split()), feature_vector[2::2])\n",
    "    feature_map    = dict(zip(feature_names,feature_values))\n",
    "    \n",
    "    # Parse a score as a float.\n",
    "    score = float(score)\n",
    "    \n",
    "    # Parse an alignment string into a list of tuples.\n",
    "    alignments = map(lambda s: tuple(map(int,s.split('-'))), alignments.strip().split(' '))\n",
    "    \n",
    "    return (k, source, target, segments, feature_map, score, alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the development data.\n",
    "dev_limit = 10\n",
    "\n",
    "with open(DEV_EN, 'r') as f:\n",
    "    inputs = [f.readline() for i in range(0, dev_limit)]\n",
    "    \n",
    "with open(DEV_DE, 'r') as f:\n",
    "    references = [f.readline() for i in range(0, dev_limit)]\n",
    "    \n",
    "with open(DEV_BEST,'r') as f:\n",
    "    candidates = []\n",
    "    candidate_set = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        candidate = parse_candidate(f.readline())\n",
    "        if candidate[0] == i:\n",
    "            candidate_set.append(candidate)\n",
    "        else:\n",
    "            candidates.append(candidate_set)\n",
    "            candidate_set = [candidate]\n",
    "            i = candidate[0]\n",
    "        if i > dev_limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the development data.\n",
    "test_limit = 10\n",
    "\n",
    "with open(TEST_EN, 'r') as f:\n",
    "    test_inputs = [f.readline() for i in range(0, dev_limit)]\n",
    "    \n",
    "with open(TEST_DE, 'r') as f:\n",
    "    test_references = [f.readline() for i in range(0, dev_limit)]\n",
    "    \n",
    "with open(TEST_BEST,'r') as f:\n",
    "    test_candidates = []\n",
    "    candidate_set = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        candidate = parse_candidate(f.readline())\n",
    "        if candidate[0] == i:\n",
    "            candidate_set.append(candidate)\n",
    "        else:\n",
    "            test_candidates.append(candidate_set)\n",
    "            candidate_set = [candidate]\n",
    "            i = candidate[0]\n",
    "        if i > dev_limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example: print all relevant information for sentence with id #2.\n",
    "print(inputs[2])\n",
    "print(references[2])\n",
    "(k, source, target, segments, feature_map, score, alignments) = candidates[2][0]\n",
    "# print(segments)\n",
    "print(feature_map.values())\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing feature vector for two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_vector(e, c1, c2):\n",
    "    \"\"\"\n",
    "    e  : source sentence\n",
    "    c1 : features from first translation\n",
    "    c2 : features from second translation\n",
    "    \"\"\"\n",
    "    (_, _, t1, _, f1, s1, _) = c1\n",
    "    (_, _, t2, _, f2, s2, _) = c2\n",
    "    \n",
    "    f1 = sum(f1.values(), [])\n",
    "    f2 = sum(f2.values(), [])\n",
    "    \n",
    "    e  = e .decode('utf-8')\n",
    "    t1 = t1.decode('utf-8')\n",
    "    t2 = t2.decode('utf-8')\n",
    "    \n",
    "    pos0 = pos_feature(e ,en_nlp)\n",
    "    pos1 = pos_feature(t1,de_nlp)\n",
    "    pos2 = pos_feature(t2,de_nlp)\n",
    "    \n",
    "    v0 = en_nlp(e).vector\n",
    "    v1 = de_nlp(t1).vector\n",
    "    v2 = de_nlp(t2).vector\n",
    "    \n",
    "    #return list(itertools.chain(f1,f2,pos0,pos1,pos2,v0,v1,v2,[s1,s2]))\n",
    "    return [sum(f1),sum(f2),pos1,pos2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_label(ref, c1, c2):\n",
    "    \n",
    "    (_, _, t1, _, _, _, _) = c1\n",
    "    (_, _, t2, _, _, _, _) = c2\n",
    "    \n",
    "    if (BLEU(ref, t1) > BLEU(ref, t2)):\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PRO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pro_corpus(inputs, references, candidates, sample_size=10):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i, e in enumerate(inputs):\n",
    "        g = references[i]\n",
    "        c = candidates[i]\n",
    "        data = data + pro(e, g, c, sample_size)\n",
    "    \n",
    "    (x,y) = zip(*data)\n",
    "    return (list(x), list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pro(e, g, c, sample_size=10):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in range(0,sample_size):\n",
    "        \n",
    "        # Randomly pick two candidates that are not the same\n",
    "        j1 = j2 = random.randint(0,len(c)-1)\n",
    "        while j1 == j2:\n",
    "            j2 = random.randint(0,len(c)-1)\n",
    "            \n",
    "        training_example = (feature_vector(e, c[j1],c[j2]), training_label(g,c[j1],c[j2]))\n",
    "        \n",
    "        data.append(training_example)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_x, train_y) = pro_corpus(inputs, references, candidates, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC()\n",
    "clf.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating test data    \n",
    "(test_x, test_y) = pro_corpus(test_inputs, test_references, test_candidates, 10)\n",
    "predicted = clf.predict(test_x)\n",
    "print(metrics.classification_report(test_y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reranking the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_sentences(inputs, candidates, clf):\n",
    "    sentences = []\n",
    "    \n",
    "    for i, e in enumerate(inputs):\n",
    "        j = i + 1000\n",
    "        c = candidates[i]\n",
    "        sentences.append(best_sentence(e, c, clf))\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_sentence(e, c, clf):\n",
    "    \n",
    "    def compare(x, y):\n",
    "        if clf.predict([feature_vector(e,x,y)]) == [0]:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    (_, _, s, _, _, _, _) = sorted(c, cmp=compare)[0]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bleu_references = [[x] for x in test_references]\n",
    "bleu_hypotheses = best_sentences(test_inputs, test_candidates, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blue = corpus_bleu(bleu_references, bleu_hypotheses) \n",
    "print(blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
